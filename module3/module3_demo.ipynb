{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - R Crosstalk (cont.)\n",
    "## Jupyter Magic\n",
    "Jupyter R magic can be used to make calls to R from Jupyter Notebooks and to return outputs from R functions into the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -o x\n",
    "x = seq(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Follow-ups\n",
    "Pandas can read tabulated data directly from URLs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x01</th>\n",
       "      <th>x02</th>\n",
       "      <th>x03</th>\n",
       "      <th>x04</th>\n",
       "      <th>x05</th>\n",
       "      <th>x06</th>\n",
       "      <th>x07</th>\n",
       "      <th>x08</th>\n",
       "      <th>x09</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tango</td>\n",
       "      <td>-5.738806</td>\n",
       "      <td>7.903669</td>\n",
       "      <td>3.322340</td>\n",
       "      <td>-0.454518</td>\n",
       "      <td>16.532828</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>1.409807</td>\n",
       "      <td>-1.245656</td>\n",
       "      <td>8.429060</td>\n",
       "      <td>-9.485051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tango</td>\n",
       "      <td>-2.924918</td>\n",
       "      <td>4.776924</td>\n",
       "      <td>3.979680</td>\n",
       "      <td>-1.592813</td>\n",
       "      <td>10.070496</td>\n",
       "      <td>0.447814</td>\n",
       "      <td>-1.497565</td>\n",
       "      <td>0.741973</td>\n",
       "      <td>5.404957</td>\n",
       "      <td>-11.145451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foxtrot</td>\n",
       "      <td>-7.371013</td>\n",
       "      <td>6.783924</td>\n",
       "      <td>3.154825</td>\n",
       "      <td>-2.325751</td>\n",
       "      <td>16.109512</td>\n",
       "      <td>0.103180</td>\n",
       "      <td>0.508613</td>\n",
       "      <td>-1.168624</td>\n",
       "      <td>9.025390</td>\n",
       "      <td>-12.657244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y       x01       x02       x03       x04        x05       x06  \\\n",
       "0    tango -5.738806  7.903669  3.322340 -0.454518  16.532828  0.108963   \n",
       "1    tango -2.924918  4.776924  3.979680 -1.592813  10.070496  0.447814   \n",
       "2  foxtrot -7.371013  6.783924  3.154825 -2.325751  16.109512  0.103180   \n",
       "\n",
       "        x07       x08       x09        x10  \n",
       "0  1.409807 -1.245656  8.429060  -9.485051  \n",
       "1 -1.497565  0.741973  5.404957 -11.145451  \n",
       "2  0.508613 -1.168624  9.025390 -12.657244  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "## Read data from URL.\n",
    "url = 'https://raw.githubusercontent.com/szorowi1/qmss2017/master/module3/random/random.csv'\n",
    "data = read_csv(url)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables can be set as new Pandas indices using the **set_index** attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be especially useful for fast indexing of specific outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr in Python: *dplython* library\n",
    "To install, open the Terminal and type:\n",
    "```\n",
    "pip install dplython\n",
    "```\n",
    "For full documentation, please see [here](https://github.com/dodger487/dplython)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dplython import DplyFrame, X, select, sift, head, mutate, group_by, summarize\n",
    "\n",
    "## Convert DataFrame to DplyFrame\n",
    "data_dply = DplyFrame(data.reset_index())\n",
    "\n",
    "## Example with sift, select, and head.\n",
    "data_dply >> sift( X.x01 < -5 ) >> select( X.x02, X.x03, X.x04 ) >> head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with mutate, group_by, and summarize.\n",
    "(data_dply >> \n",
    "  mutate(x01_bin=X.x01.round()) >> \n",
    "  group_by(X.y, X.x01_bin) >> \n",
    "  summarize(x02_mean=X.x02.mean())) >> head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr in Python: *pandas-ply* library\n",
    "To install, open the Terminal and type:\n",
    "```\n",
    "pip install pandas-ply\n",
    "```\n",
    "For full documentation, please see [here](https://pythonhosted.org/pandas-ply/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_ply import install_ply, X, sym_call\n",
    "\n",
    "## After calling install_ply, all pandas objects have \n",
    "## pandas-plyâ€˜s methods attached.\n",
    "install_ply(pd)\n",
    "\n",
    "## Piping example.\n",
    "(data\n",
    " .reset_index()\n",
    " .groupby('y')\n",
    " .ply_select(\n",
    "    arr = X.x01.mean(),\n",
    "    dep = X.x02.mean())\n",
    " .ply_where(X.arr < -5, X.dep > 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr in Python: *rpy2* library\n",
    "\n",
    "For more information, please see [here](http://blog.yhat.com/posts/rpy2-combing-the-power-of-r-and-python.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import functions from R, use **robjects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "\n",
    "seq = robjects.r('seq')\n",
    "seq(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import whole libraries, use **importr**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "lme4 = importr('lme4')\n",
    "lme4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Tutorial\n",
    "\n",
    "The following will be a brief overview of machine learning with python. For more complete treatments, please see:\n",
    "* [Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)\n",
    "* [Python Machine Learning](https://github.com/rasbt/python-machine-learning-book)\n",
    "* [Intro to Neural Nets and Machine Learning](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/)\n",
    "\n",
    "## Overview\n",
    "Scikit-Learn, or sklearn, is the foremost machine learning library in Python. It is comprehensive, robust, fast, and [well-documented](http://scikit-learn.org/stable/index.html). \n",
    "\n",
    "Scikit-Learn is structured such that all of its core functions are implemented as **classes**. This means that almost every method and algorithm in Scikit-Learn is its own Pythonic type, like a *string* or *list*, and has its own built-in functions (i.e. attributes). Importantly, Scikit-Learn was written such that **the most important attributes (self-contained functions) are callable for every algorithm**. In other words, the method that works for running a Support Vector Machine is the same method that works for running a Random Forest model. This makes Scikit-Learn ideally optimized for plug-and-play in fitting models to data.\n",
    "\n",
    "The most common and important attributes that we will encounter are:\n",
    "* **fit:** train a model on some data.\n",
    "* **transform:** transform some data based on a preexisting model fit.\n",
    "* **fit_transform:** combination of *fit* and *transform*. \n",
    "* **predict:** predict an outcome based on some observed datapoints and a preexisting model fit.\n",
    "* **score:** compute the predictive accuracy of a fitted model based on some features and outcomes. (For all available scores, see the following [documentation](http://scikit-learn.org/stable/modules/model_evaluation.html).)\n",
    "\n",
    "Secondarily important attributes (i.e. present for some but not most methods):\n",
    "* **get_support:** a Boolean array indicating where certain features are present or absent. \n",
    "* **coef_:** the coefficients from a fitted model.\n",
    "* **score_:** the predictive accuracy scores stored in a model fit.\n",
    "\n",
    "In general, the workflow for fitting a model with Scikit-Learn will be to:\n",
    "1. **Initialization:** initialize an algorithm with desired parameters.\n",
    "2. **Fitting:** fit the algorithm to some data.\n",
    "3. **Transform:** transform data based on model fit. Examples might include dimensionality reduction or predicting outcomes from observations.\n",
    "\n",
    "Scikit-Learn also supports **chaining** and **piping** such that long series of functions can be strung together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Coding\n",
    "Data coding describes processes related to preprocessing of the data, such as rescaling and recoding data for use in fitting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x01</th>\n",
       "      <th>x02</th>\n",
       "      <th>x03</th>\n",
       "      <th>x04</th>\n",
       "      <th>x05</th>\n",
       "      <th>x06</th>\n",
       "      <th>x07</th>\n",
       "      <th>x08</th>\n",
       "      <th>x09</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.891</td>\n",
       "      <td>7.529</td>\n",
       "      <td>2.308</td>\n",
       "      <td>-1.696</td>\n",
       "      <td>14.056</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-1.144</td>\n",
       "      <td>9.118</td>\n",
       "      <td>-10.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.844</td>\n",
       "      <td>1.713</td>\n",
       "      <td>1.446</td>\n",
       "      <td>0.774</td>\n",
       "      <td>3.186</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.388</td>\n",
       "      <td>1.143</td>\n",
       "      <td>2.134</td>\n",
       "      <td>2.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.369</td>\n",
       "      <td>2.556</td>\n",
       "      <td>-2.724</td>\n",
       "      <td>-3.745</td>\n",
       "      <td>3.924</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-3.028</td>\n",
       "      <td>-3.837</td>\n",
       "      <td>4.234</td>\n",
       "      <td>-16.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.848</td>\n",
       "      <td>6.399</td>\n",
       "      <td>1.417</td>\n",
       "      <td>-2.230</td>\n",
       "      <td>11.950</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>-2.021</td>\n",
       "      <td>7.583</td>\n",
       "      <td>-12.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.843</td>\n",
       "      <td>7.577</td>\n",
       "      <td>2.360</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>13.769</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.206</td>\n",
       "      <td>-1.246</td>\n",
       "      <td>9.175</td>\n",
       "      <td>-10.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.825</td>\n",
       "      <td>8.756</td>\n",
       "      <td>3.168</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>16.112</td>\n",
       "      <td>0.471</td>\n",
       "      <td>1.237</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>10.623</td>\n",
       "      <td>-9.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.861</td>\n",
       "      <td>13.242</td>\n",
       "      <td>5.982</td>\n",
       "      <td>0.216</td>\n",
       "      <td>23.396</td>\n",
       "      <td>0.910</td>\n",
       "      <td>3.718</td>\n",
       "      <td>2.099</td>\n",
       "      <td>14.949</td>\n",
       "      <td>-5.868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x01      x02      x03      x04      x05      x06      x07      x08  \\\n",
       "count  200.000  200.000  200.000  200.000  200.000  200.000  200.000  200.000   \n",
       "mean    -5.891    7.529    2.308   -1.696   14.056    0.344    0.180   -1.144   \n",
       "std      2.844    1.713    1.446    0.774    3.186    0.205    1.388    1.143   \n",
       "min    -12.369    2.556   -2.724   -3.745    3.924   -0.250   -3.028   -3.837   \n",
       "25%     -7.848    6.399    1.417   -2.230   11.950    0.209   -0.745   -2.021   \n",
       "50%     -5.843    7.577    2.360   -1.637   13.769    0.362    0.206   -1.246   \n",
       "75%     -3.825    8.756    3.168   -1.184   16.112    0.471    1.237   -0.322   \n",
       "max      3.861   13.242    5.982    0.216   23.396    0.910    3.718    2.099   \n",
       "\n",
       "           x09      x10  \n",
       "count  200.000  200.000  \n",
       "mean     9.118  -10.725  \n",
       "std      2.134    2.023  \n",
       "min      4.234  -16.374  \n",
       "25%      7.583  -12.015  \n",
       "50%      9.175  -10.644  \n",
       "75%     10.623   -9.386  \n",
       "max     14.949   -5.868  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "## Read data from URL.\n",
    "url = 'https://raw.githubusercontent.com/szorowi1/qmss2017/master/module3/random/random.csv'\n",
    "data = read_csv(url)\n",
    "data = data.set_index('y')\n",
    "\n",
    "\n",
    "data.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foxtrot</th>\n",
       "      <th>hotel</th>\n",
       "      <th>tango</th>\n",
       "      <th>yankee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foxtrot  hotel  tango  yankee\n",
       "0        0      0      1       0\n",
       "1        0      0      1       0\n",
       "2        1      0      0       0\n",
       "3        1      0      0       0\n",
       "4        0      0      0       1\n",
       "5        0      0      1       0\n",
       "6        1      0      0       0\n",
       "7        0      1      0       0\n",
       "8        1      0      0       0\n",
       "9        0      0      1       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import get_dummies\n",
    "\n",
    "## Make dummy coded variables.\n",
    "get_dummies(data.index).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digitizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.739\t2\n",
      "-5.317\t2\n",
      "-7.521\t1\n",
      "-3.429\t3\n",
      "-10.959\t0\n",
      "-9.192\t0\n",
      "-1.550\t4\n",
      "-7.833\t1\n",
      "-4.926\t3\n",
      "-10.388\t0\n"
     ]
    }
   ],
   "source": [
    "## Define bins.\n",
    "bins = [-9,-7,-5,-3,-1]\n",
    "\n",
    "x = data.x01\n",
    "xd = np.digitize(x, bins)\n",
    "\n",
    "for a,b in np.c_[x,xd][::20]:\n",
    "    print('%0.3f\\t%0.0f' %(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Scikit-Learn includes several built-in preprocessing algorithms for transforming/recoding data:\n",
    "* **StandardScaler:** scales a variable such that it is mean = 0, sd = 1\n",
    "* **RobustScaler:** scales a variable using medians and quartiles (i.e. 25% of data falls beneath 1st quartile)\n",
    "* **MinMaxScaler:** scales a variable between a specified min and max (e.g. [0,1])\n",
    "* **Normalizer:** scales each data point such that the feature vector has a euclidean length of one\n",
    "\n",
    "We will test two of these now, applying the RobustScaler to all continous data and the MinMaxScaler to all nominal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x01</th>\n",
       "      <th>x02</th>\n",
       "      <th>x03</th>\n",
       "      <th>x04</th>\n",
       "      <th>x05</th>\n",
       "      <th>x06</th>\n",
       "      <th>x07</th>\n",
       "      <th>x08</th>\n",
       "      <th>x09</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.283</td>\n",
       "      <td>-2.910</td>\n",
       "      <td>-3.487</td>\n",
       "      <td>-2.654</td>\n",
       "      <td>-3.188</td>\n",
       "      <td>-2.902</td>\n",
       "      <td>-2.318</td>\n",
       "      <td>-2.363</td>\n",
       "      <td>-2.295</td>\n",
       "      <td>-2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.691</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.660</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.438</td>\n",
       "      <td>3.343</td>\n",
       "      <td>2.547</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.939</td>\n",
       "      <td>2.768</td>\n",
       "      <td>2.556</td>\n",
       "      <td>2.845</td>\n",
       "      <td>2.740</td>\n",
       "      <td>2.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x01      x02      x03      x04      x05      x06      x07      x08  \\\n",
       "count  200.000  200.000  200.000  200.000  200.000  200.000  200.000  200.000   \n",
       "mean     0.000   -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   \n",
       "std      1.003    1.003    1.003    1.003    1.003    1.003    1.003    1.003   \n",
       "min     -2.283   -2.910   -3.487   -2.654   -3.188   -2.902   -2.318   -2.363   \n",
       "25%     -0.690   -0.661   -0.617   -0.691   -0.662   -0.660   -0.669   -0.769   \n",
       "50%      0.017    0.028    0.036    0.077   -0.090    0.086    0.019   -0.090   \n",
       "75%      0.728    0.718    0.597    0.664    0.647    0.622    0.763    0.721   \n",
       "max      3.438    3.343    2.547    2.479    2.939    2.768    2.556    2.845   \n",
       "\n",
       "           x09      x10  \n",
       "count  200.000  200.000  \n",
       "mean    -0.000    0.000  \n",
       "std      1.003    1.003  \n",
       "min     -2.295   -2.800  \n",
       "25%     -0.721   -0.639  \n",
       "50%      0.027    0.040  \n",
       "75%      0.707    0.663  \n",
       "max      2.740    2.407  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Apply standard-score (z-score) transform to data. \n",
    "data.loc[:,:] = StandardScaler().fit_transform(data.loc[:,:])\n",
    "\n",
    "data.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Inflation Factor\n",
    "The **variance inflation factor (VIF)** is a measure of collinearity, and tests for the increase of the variance of the parameter estimates if an additional variable is added to the linear regression. Statsmodels includes a variance inflation factor function. \n",
    "\n",
    "One form of collinearity can be inspected from inspecting the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "%matplotlib inline\n",
    "\n",
    "sns.heatmap(data.corr(), vmin=-1, vmax=1, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variance_inflation_factor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteratively compute the VIF and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute VIF.\n",
    "VIF = [variance_inflation_factor(data.as_matrix(), n) for n in range(data.shape[-1])]\n",
    "\n",
    "## Plot.\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "color, = sns.color_palette(n_colors=1)\n",
    "ax = sns.barplot(np.arange(data.shape[-1]), VIF, color=color);\n",
    "ax.set(xticklabels=data.columns,  ylabel='VIF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the collinear variable, recompute VIF, and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop column x09.\n",
    "data = data.drop('x09', axis=1)\n",
    "\n",
    "## Compute VIF.\n",
    "VIF = [variance_inflation_factor(data.as_matrix(), n) for n in range(data.shape[-1])]\n",
    "\n",
    "## Plot.\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "color, = sns.color_palette(n_colors=1)\n",
    "ax = sns.barplot(np.arange(data.shape[-1]), VIF, color=color);\n",
    "ax.set(xticklabels=data.columns, ylim=(0,15), ylabel='VIF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Scikit-Learn also includes a number of features for the automatic reduction of features to those most predictive of an outcome. All feature selection methods can be found under **sklearn.feature_selection**. Preexisting methods include:\n",
    "\n",
    "|Method|Description|Example|\n",
    "|------|-----------|-------|\n",
    "|Univariate| Selection of features with statistically significant relationships to the target. These approaches only consider each feature individually.| SelectKBest, SelectPercentile, SelectFdr, SelectFwe|\n",
    "|Model-based approaches| Use a supervised machine learning model to judge the importance of features and keep only the most important|SelectFromModel|\n",
    "|Iterative selection| Build a series of models, either through adding or removing features one-by-one, and stopping when some stopping criterion is reached.| RFE, RFECV |\n",
    "\n",
    "<br>We will demonstrate feature selection with the simpler univariate approaches, specifically **SelectFwe**, which selects only statistically significant features after controlling for multiple comparisons with family-wise error (FWE) corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, SelectFdr, SelectFwe\n",
    "\n",
    "## Initialize feature selection classes.\n",
    "fwe = SelectFwe(alpha=0.05)\n",
    "\n",
    "## Fit to data.\n",
    "fit = fwe.fit(data, data.index)\n",
    "\n",
    "## Find surviving columns.\n",
    "fwe_cols = fit.get_support()\n",
    "fwe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn attributes can be **chained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwe_cols = SelectFwe(alpha=0.05).fit(data,data.index).get_support()\n",
    "fwe_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce data to surviving columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.columns[fwe_cols]]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## Initialize with desired number of components.\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "## Fit to data.\n",
    "fit = pca.fit(data)\n",
    "print(fit.explained_variance_ratio_)\n",
    "\n",
    "## Transform.\n",
    "data_2d = fit.transform(data)\n",
    "print(data_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "## Fit into DataFrame.\n",
    "data_2d = DataFrame(fit.transform(data), columns=('PCA1','PCA2'), index=data.index)\n",
    "\n",
    "## Plot.\n",
    "y_types = data_2d.index.unique()\n",
    "colors = sns.color_palette(n_colors=len(y_types))\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "for y, color in zip(y_types, colors):\n",
    "    ax.scatter(data_2d.loc[y, 'PCA1'], data_2d.loc[y, 'PCA2'], color=color, label=y)\n",
    "ax.set(xlabel='PCA1', ylabel='PCA2')\n",
    "ax.legend(loc=7, bbox_to_anchor=(1.25,0.5), handletextpad=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Sets\n",
    "Scikit-learn contains a function, **train_test_split**, that shuffles the dataset and splits it for you. This is perhaps the most essential function in all of Scikit-Learn. Fortunately it handles Pandas arrays making it easily compatible with any data that can be read into Python via Pandas. We demonstrate this function below on the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Separate out precictors and outcomes.\n",
    "X = data.as_matrix()\n",
    "y = data.index\n",
    "\n",
    "## Split our dataset into four variables using train_test_split.\n",
    "## We hold out 20% of the data for prediction. All but the last\n",
    "## column are predictors.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=0)\n",
    "\n",
    "print('Original data shape: (%s, %s)' %data.shape)\n",
    "print('Train data shape: (%s, %s)' %X_train.shape)\n",
    "print('Test data shape: (%s, %s)' %X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## Initialize SVC with desired parameteres.\n",
    "svc = LinearSVC(penalty='l2', C=1.0, random_state=0)\n",
    "\n",
    "## Fit to data.\n",
    "fit = svc.fit(X_train, y_train)\n",
    "\n",
    "## Compute predictive accuracy to test data.\n",
    "print('Training performance: %0.3f' %fit.score(X_train, y_train))\n",
    "print('Test performance: %0.3f' %fit.score(X_test, y_test))\n",
    "\n",
    "## Show predictions.\n",
    "predictions = fit.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confmat = DataFrame(confusion_matrix(y_test, predictions), columns=np.unique(y_test), \n",
    "                    index=np.unique(y_test))\n",
    "confmat = confmat.apply(lambda x: x / x.sum(), 1)\n",
    "\n",
    "confmat.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "One downside to train_test_split is that it splits the data only once. This can be problematic as that one model fit may be unrepresentative of the underlying true model fit as a result of the random allocation of data to the train/test sets. Thus, it is better to test models on multiple sets of the data. Fortunately, Scikit-Learn has many [built-in functions](http://scikit-learn.org/stable/modules/cross_validation.html) for sampling and resampling train/test sets:\n",
    "* **K-fold:** divides all the samples in k groups of samples, called folds of equal sizes (if possible). The prediction function is learned using k - 1 folds, and the fold left out is used for test.\n",
    "* **Leave One Out (LOO):** each learning set is created by taking all the samples except one, the test set being the sample left out. This cross-validation procedure does not waste much data as only one sample is removed from the training set.\n",
    "* **Leave P Out (LPO):** very similar to LeaveOneOut as it creates all the possible training/test sets by removing p samples from the complete set.\n",
    "* **Shuffle & Split:** generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.\n",
    "* **Stratified k-fold:** variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "* **Stratified Shuffle & Split:**  variation of ShuffleSplit, which returns stratified splits, i.e which creates splits by preserving the same percentage for each target class as in the complete set.\n",
    "\n",
    "We demonstrate two of these functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "StratifiedShuffleSplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "for train_ix, test_ix in sss.split(X, y):\n",
    "    print(train_ix.shape, test_ix.shape)\n",
    "    \n",
    "print(train_ix[:10])\n",
    "print(test_ix[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the effect of training size on training and test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define train sizes.\n",
    "train_sizes = np.linspace(0.2,0.8,13)\n",
    "n_train_sizes = train_sizes.shape[0]\n",
    "n_splits = 25\n",
    "test_size = 0.2\n",
    "\n",
    "## Preallocate space for performance data.\n",
    "performance = np.zeros((n_train_sizes,n_splits,3))\n",
    "\n",
    "## Iteratively compute scores.\n",
    "for i, train_size in enumerate(train_sizes):\n",
    "    \n",
    "    ## Initialize cross-validation tool.\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, train_size=train_size, \n",
    "                                 test_size=test_size, random_state=0)\n",
    "    \n",
    "    for j, indices in enumerate(sss.split(X,y)):\n",
    "        \n",
    "        ## Extract indices.\n",
    "        train_ix, test_ix = indices\n",
    "        \n",
    "        ## Fit SVC.\n",
    "        fit = svc.fit(X[train_ix], y[train_ix])\n",
    "        \n",
    "        ## Compute performance scores.\n",
    "        train_score = fit.score(X[train_ix], y[train_ix])\n",
    "        test_score = fit.score(X[test_ix], y[test_ix])\n",
    "        \n",
    "        ## Store information.\n",
    "        performance[i,j,0] = train_size\n",
    "        performance[i,j,1] = train_score\n",
    "        performance[i,j,2] = test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to DataFrame.\n",
    "performance = DataFrame(performance.reshape(n_train_sizes*n_splits,3), \n",
    "                        columns=('Train Size','Train', 'Test'))\n",
    "\n",
    "## Melt into longlist.\n",
    "performance = performance.melt(id_vars='Train Size', var_name='Model', value_name='Score')\n",
    "\n",
    "## Plot.\n",
    "sns.factorplot('Train Size', 'Score', 'Model', data=performance, aspect=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the effect of sparsity-inducing parameters on model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define parameters.\n",
    "C_params = np.power( 10., [-2, -1, 0, 1, 2] )\n",
    "n_c_params = C_params.shape[0]\n",
    "kfold = 10\n",
    "\n",
    "## Preallocate space for performance data.\n",
    "performance = np.zeros((n_c_params,kfold,2))\n",
    "\n",
    "for i, C in enumerate(C_params):\n",
    "    \n",
    "    ## Initialize SVC.\n",
    "    svc = LinearSVC(penalty='l2', C=C, random_state=0)\n",
    "    \n",
    "    ## Perform cross-validation.\n",
    "    scores = cross_val_score(svc, X, y, cv=kfold)\n",
    "    \n",
    "    ## Store.\n",
    "    performance[i,:,0] = C\n",
    "    performance[i,:,1] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to DataFrame.\n",
    "performance = DataFrame(performance.reshape(n_c_params*kfold,2), columns=('C','Score'))\n",
    "\n",
    "## Plot.\n",
    "sns.swarmplot('C','Score',data=performance);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
